{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvR9TdAM4WK"
      },
      "source": [
        "# RAG with LangChain ðŸ¦œðŸ”—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ODfzg0h2M4WL"
      },
      "outputs": [],
      "source": [
        "# requirements for this example:\n",
        "%pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2S-H8nrBM4WM",
        "outputId": "860b9dad-429a-4681-e2af-0c64f737402b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhp9Of1DM4WM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaGCW7LdM4WM"
      },
      "source": [
        "### Loader and splitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUveMUNM4WM"
      },
      "source": [
        "Below we set up:\n",
        "- a `Loader` which will be used to create LangChain documents, and\n",
        "- a splitter, which will be used to split these documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JWZpaJ8hM4WN"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from langchain_core.document_loaders import BaseLoader\n",
        "from langchain_core.documents import Document as LCDocument\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "class DoclingPDFLoader(BaseLoader):\n",
        "\n",
        "    def __init__(self, file_path: str | list[str]) -> None:\n",
        "        self._file_paths = file_path if isinstance(file_path, list) else [file_path]\n",
        "        self._converter = DocumentConverter()\n",
        "\n",
        "    def lazy_load(self) -> Iterator[LCDocument]:\n",
        "        for source in self._file_paths:\n",
        "            dl_doc = self._converter.convert(source).document\n",
        "            text = dl_doc.export_to_markdown()\n",
        "            yield LCDocument(page_content=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4jZp1B7wM4WN"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = \"https://raw.githubusercontent.com/DS4SD/docling/main/tests/data/2206.01062.pdf\"  # DocLayNet paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4QNX07SjM4WN"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = DoclingPDFLoader(file_path=FILE_PATH)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aON0eshM4WN"
      },
      "source": [
        "We now used the above-defined objects to get the document splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GeIaFWQuM4WN"
      },
      "outputs": [],
      "source": [
        "docs = loader.load()\n",
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7m1x1YjM4WN"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MwXuxsbaM4WO"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "HF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ5bgMWxM4WO"
      },
      "source": [
        "### Vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lu4lgYeOM4WO",
        "outputId": "e3820ee7-77f2-4535-b94d-c23846c79f44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-07 10:17:05,652 [ERROR][handler]: RPC error: [create_index], <MilvusException: (code=65535, message=invalid index type: HNSW, local mode only support FLAT IVF_FLAT AUTOINDEX: )>, <Time:{'RPC start': '2025-01-07 10:17:05.648941', 'RPC error': '2025-01-07 10:17:05.651935'}> (decorators.py:140)\n"
          ]
        }
      ],
      "source": [
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "MILVUS_URI = os.environ.get(\n",
        "    \"MILVUS_URI\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\"\n",
        ")\n",
        "\n",
        "vectorstore = Milvus.from_documents(\n",
        "    splits,\n",
        "    embeddings,\n",
        "    connection_args={\"uri\": MILVUS_URI},\n",
        "    drop_old=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TBv3kbYM4WO"
      },
      "source": [
        "### LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZDUWTL1DM4WO"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "HF_API_KEY = os.environ.get(\"HF_API_KEY\")\n",
        "HF_LLM_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=HF_LLM_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvTb3WpvM4WO"
      },
      "source": [
        "## RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T5yJtthvM4WO"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "from langchain_core.documents import Document as LCDocument\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def format_docs(docs: Iterable[LCDocument]):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\"\n",
        ")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nGfojb9xM4WP",
        "outputId": "505ec2fb-f846-49d8-b1a9-689ed4b8ff30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n7059 pages were human annotated for DocLayNet.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "rag_chain.invoke(\"How many pages were human annotated for DocLayNet?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}